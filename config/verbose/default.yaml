data:
  data_root_dir: /private/home/nvivek/VQA/training_data/
  dataset: vizwiz
  image_depth_first: false
  image_fast_reader: true
  image_feat_train:
  - rcnn_adaptive_vizwiz/vizwiz
  image_feat_val:
  - rcnn_adaptive_vizwiz/vizwiz
  image_max_loc: 103
  imdb_file_train:
  - imdb/imdb_vizwiz_val.npy
  imdb_file_val:
  - imdb/imdb_vizwiz_train.npy
  vocab_answer_file: answers_vizwiz.txt
  vocab_question_file: vocabulary_vizwiz.txt
model:
  question_embedding:
  - method: att_que_embed
    par:
      embedding_init_file: vizwiz_glove.6B.300d.txt.npy
  image_feature_encoding:
  - method: default_image
    par: {}
training_parameters:
  clip_norm_mode: all
  lr_ratio: 0.01
  lr_steps:
  - 10000
  - 12000
  - 14000
  max_grad_l2_norm: 0.25
  max_iter: 15000
  report_interval: 100
  snapshot_interval: 1000
  wu_factor: 0.2
  wu_iters: 1000
